{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8734f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05:09:10:40,209 INFO     [lm_eval.__main__:379] Selected Tasks: ['mmlu', 'wmdp']\n",
      "2025-06-05:09:10:40,211 INFO     [lm_eval.evaluator:169] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42\n",
      "2025-06-05:09:10:40,211 INFO     [lm_eval.evaluator:206] Initializing hf model, with arguments: {'pretrained': '/home/ubuntu/thesis/code/rmu_results/layer9_alpha300.0_steer750.0', 'dtype': 'bfloat16'}\n",
      "2025-06-05:09:10:40,277 INFO     [lm_eval.models.huggingface:136] Using device 'cuda'\n",
      "2025-06-05:09:10:43,622 INFO     [lm_eval.models.huggingface:376] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.84it/s]\n",
      "2025-06-05:09:10:44,890 INFO     [lm_eval.models.huggingface:223] Model type is 'gemma2', part of the Gemma family--a BOS token will be used as Gemma underperforms without it.\n",
      "2025-06-05:09:10:59,933 WARNING  [lm_eval.api.task:327] [Task: wmdp_cyber] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2025-06-05:09:10:59,933 WARNING  [lm_eval.api.task:327] [Task: wmdp_cyber] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2025-06-05:09:11:00,480 WARNING  [lm_eval.api.task:327] [Task: wmdp_chem] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2025-06-05:09:11:00,481 WARNING  [lm_eval.api.task:327] [Task: wmdp_chem] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2025-06-05:09:11:00,792 WARNING  [lm_eval.api.task:327] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2025-06-05:09:11:00,792 WARNING  [lm_eval.api.task:327] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2025-06-05:09:11:00,833 INFO     [lm_eval.api.task:420] Building contexts for wmdp_bio on rank 0...\n",
      "100%|██████████████████████████████████████| 1273/1273 [00:01<00:00, 815.79it/s]\n",
      "2025-06-05:09:11:02,430 INFO     [lm_eval.api.task:420] Building contexts for wmdp_chem on rank 0...\n",
      "100%|████████████████████████████████████████| 408/408 [00:00<00:00, 816.37it/s]\n",
      "2025-06-05:09:11:02,943 INFO     [lm_eval.api.task:420] Building contexts for wmdp_cyber on rank 0...\n",
      "100%|██████████████████████████████████████| 1987/1987 [00:02<00:00, 823.91it/s]\n",
      "2025-06-05:09:11:05,417 INFO     [lm_eval.api.task:420] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 803.17it/s]\n",
      "2025-06-05:09:11:05,546 INFO     [lm_eval.api.task:420] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 805.58it/s]\n",
      "2025-06-05:09:11:05,731 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 818.16it/s]\n",
      "2025-06-05:09:11:05,857 INFO     [lm_eval.api.task:420] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 858.44it/s]\n",
      "2025-06-05:09:11:06,032 INFO     [lm_eval.api.task:420] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 857.72it/s]\n",
      "2025-06-05:09:11:06,488 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 879.33it/s]\n",
      "2025-06-05:09:11:06,742 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 868.09it/s]\n",
      "2025-06-05:09:11:06,922 INFO     [lm_eval.api.task:420] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 816.55it/s]\n",
      "2025-06-05:09:11:07,064 INFO     [lm_eval.api.task:420] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 783.95it/s]\n",
      "2025-06-05:09:11:07,196 INFO     [lm_eval.api.task:420] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 784.37it/s]\n",
      "2025-06-05:09:11:07,396 INFO     [lm_eval.api.task:420] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 836.81it/s]\n",
      "2025-06-05:09:11:07,519 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 866.51it/s]\n",
      "2025-06-05:09:11:07,762 INFO     [lm_eval.api.task:420] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 860.39it/s]\n",
      "2025-06-05:09:11:07,885 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 860.39it/s]\n",
      "2025-06-05:09:11:08,209 INFO     [lm_eval.api.task:420] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 873.31it/s]\n",
      "2025-06-05:09:11:08,327 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 490.74it/s]\n",
      "2025-06-05:09:11:08,970 INFO     [lm_eval.api.task:420] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 821.64it/s]\n",
      "2025-06-05:09:11:09,096 INFO     [lm_eval.api.task:420] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 806.50it/s]\n",
      "2025-06-05:09:11:09,397 INFO     [lm_eval.api.task:420] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 839.53it/s]\n",
      "2025-06-05:09:11:09,563 INFO     [lm_eval.api.task:420] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 805.33it/s]\n",
      "2025-06-05:09:11:09,924 INFO     [lm_eval.api.task:420] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 793.31it/s]\n",
      "2025-06-05:09:11:10,269 INFO     [lm_eval.api.task:420] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 791.24it/s]\n",
      "2025-06-05:09:11:10,574 INFO     [lm_eval.api.task:420] Building contexts for mmlu_nutrition on rank 0...\n",
      "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 809.25it/s]\n",
      "2025-06-05:09:11:10,965 INFO     [lm_eval.api.task:420] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 783.61it/s]\n",
      "2025-06-05:09:11:11,097 INFO     [lm_eval.api.task:420] Building contexts for mmlu_business_ethics on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 855.94it/s]\n",
      "2025-06-05:09:11:11,219 INFO     [lm_eval.api.task:420] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 847.25it/s]\n",
      "2025-06-05:09:11:11,551 INFO     [lm_eval.api.task:420] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|████████████████████████████████████████| 783/783 [00:00<00:00, 815.76it/s]\n",
      "2025-06-05:09:11:12,541 INFO     [lm_eval.api.task:420] Building contexts for mmlu_management on rank 0...\n",
      "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 841.33it/s]\n",
      "2025-06-05:09:11:12,667 INFO     [lm_eval.api.task:420] Building contexts for mmlu_virology on rank 0...\n",
      "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 839.81it/s]\n",
      "2025-06-05:09:11:12,871 INFO     [lm_eval.api.task:420] Building contexts for mmlu_college_medicine on rank 0...\n",
      "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 865.45it/s]\n",
      "2025-06-05:09:11:13,078 INFO     [lm_eval.api.task:420] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 864.05it/s]\n",
      "2025-06-05:09:11:13,198 INFO     [lm_eval.api.task:420] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 872.18it/s]\n",
      "2025-06-05:09:11:13,462 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 871.86it/s]\n",
      "2025-06-05:09:11:13,744 INFO     [lm_eval.api.task:420] Building contexts for mmlu_security_studies on rank 0...\n",
      "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 873.90it/s]\n",
      "2025-06-05:09:11:14,034 INFO     [lm_eval.api.task:420] Building contexts for mmlu_econometrics on rank 0...\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 895.22it/s]\n",
      "2025-06-05:09:11:14,166 INFO     [lm_eval.api.task:420] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 878.59it/s]\n",
      "2025-06-05:09:11:14,283 INFO     [lm_eval.api.task:420] Building contexts for mmlu_public_relations on rank 0...\n",
      "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 866.77it/s]\n",
      "2025-06-05:09:11:14,415 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 850.85it/s]\n",
      "2025-06-05:09:11:14,888 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 790.77it/s]\n",
      "2025-06-05:09:11:15,147 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 806.06it/s]\n",
      "2025-06-05:09:11:15,845 INFO     [lm_eval.api.task:420] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 849.18it/s]\n",
      "2025-06-05:09:11:16,004 INFO     [lm_eval.api.task:420] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 842.61it/s]\n",
      "2025-06-05:09:11:16,755 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 816.84it/s]\n",
      "2025-06-05:09:11:16,999 INFO     [lm_eval.api.task:420] Building contexts for mmlu_sociology on rank 0...\n",
      "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 801.94it/s]\n",
      "2025-06-05:09:11:17,258 INFO     [lm_eval.api.task:420] Building contexts for mmlu_prehistory on rank 0...\n",
      "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 784.77it/s]\n",
      "2025-06-05:09:11:17,684 INFO     [lm_eval.api.task:420] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 799.18it/s]\n",
      "2025-06-05:09:11:17,823 INFO     [lm_eval.api.task:420] Building contexts for mmlu_professional_law on rank 0...\n",
      "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 754.14it/s]\n",
      "2025-06-05:09:11:19,918 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 814.10it/s]\n",
      "2025-06-05:09:11:20,219 INFO     [lm_eval.api.task:420] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 843.13it/s]\n",
      "2025-06-05:09:11:21,314 INFO     [lm_eval.api.task:420] Building contexts for mmlu_formal_logic on rank 0...\n",
      "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 886.04it/s]\n",
      "2025-06-05:09:11:21,461 INFO     [lm_eval.api.task:420] Building contexts for mmlu_international_law on rank 0...\n",
      "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 892.90it/s]\n",
      "2025-06-05:09:11:21,601 INFO     [lm_eval.api.task:420] Building contexts for mmlu_philosophy on rank 0...\n",
      "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 801.67it/s]\n",
      "2025-06-05:09:11:22,001 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 789.92it/s]\n",
      "2025-06-05:09:11:22,217 INFO     [lm_eval.api.task:420] Building contexts for mmlu_world_religions on rank 0...\n",
      "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 822.01it/s]\n",
      "2025-06-05:09:11:22,431 INFO     [lm_eval.api.task:420] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 797.35it/s]\n",
      "2025-06-05:09:11:22,877 INFO     [lm_eval.api.task:420] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 782.71it/s]\n",
      "2025-06-05:09:11:23,147 INFO     [lm_eval.api.task:420] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 782.44it/s]\n",
      "2025-06-05:09:11:23,363 INFO     [lm_eval.evaluator:517] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|████| 70840/70840 [04:16<00:00, 276.17it/s]\n",
      "2025-06-05:09:16:24,876 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated\n",
      "2025-06-05:09:16:24,889 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_abstract_algebra\n",
      "2025-06-05:09:16:24,895 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_anatomy\n",
      "2025-06-05:09:16:24,904 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_astronomy\n",
      "2025-06-05:09:16:24,915 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_business_ethics\n",
      "2025-06-05:09:16:24,922 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_clinical_knowledge\n",
      "2025-06-05:09:16:24,939 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_college_biology\n",
      "2025-06-05:09:16:24,950 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_college_chemistry\n",
      "2025-06-05:09:16:24,957 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_college_computer_science\n",
      "2025-06-05:09:16:24,966 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_college_mathematics\n",
      "2025-06-05:09:16:24,973 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_college_medicine\n",
      "2025-06-05:09:16:24,987 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_college_physics\n",
      "2025-06-05:09:16:24,994 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_computer_security\n",
      "2025-06-05:09:16:25,421 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_conceptual_physics\n",
      "2025-06-05:09:16:25,435 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_econometrics\n",
      "2025-06-05:09:16:25,442 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_electrical_engineering\n",
      "2025-06-05:09:16:25,451 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_elementary_mathematics\n",
      "2025-06-05:09:16:25,477 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_formal_logic\n",
      "2025-06-05:09:16:25,488 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_global_facts\n",
      "2025-06-05:09:16:25,494 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_biology\n",
      "2025-06-05:09:16:25,517 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_chemistry\n",
      "2025-06-05:09:16:25,536 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_computer_science\n",
      "2025-06-05:09:16:25,544 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_european_history\n",
      "2025-06-05:09:16:25,565 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_geography\n",
      "2025-06-05:09:16:25,579 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_government_and_politics\n",
      "2025-06-05:09:16:25,592 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_macroeconomics\n",
      "2025-06-05:09:16:25,617 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_mathematics\n",
      "2025-06-05:09:16:25,636 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_microeconomics\n",
      "2025-06-05:09:16:25,651 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_physics\n",
      "2025-06-05:09:16:25,662 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_psychology\n",
      "2025-06-05:09:16:25,699 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_statistics\n",
      "2025-06-05:09:16:25,715 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_us_history\n",
      "2025-06-05:09:16:25,739 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_high_school_world_history\n",
      "2025-06-05:09:16:25,769 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_human_aging\n",
      "2025-06-05:09:16:25,784 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_human_sexuality\n",
      "2025-06-05:09:16:25,793 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_international_law\n",
      "2025-06-05:09:16:25,801 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_jurisprudence\n",
      "2025-06-05:09:16:25,808 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_logical_fallacies\n",
      "2025-06-05:09:16:25,820 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_machine_learning\n",
      "2025-06-05:09:16:25,828 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_management\n",
      "2025-06-05:09:16:25,835 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_marketing\n",
      "2025-06-05:09:16:25,850 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_medical_genetics\n",
      "2025-06-05:09:16:25,859 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_miscellaneous\n",
      "2025-06-05:09:16:25,905 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_moral_disputes\n",
      "2025-06-05:09:16:25,928 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_moral_scenarios\n",
      "2025-06-05:09:16:25,991 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_nutrition\n",
      "2025-06-05:09:16:26,011 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_philosophy\n",
      "2025-06-05:09:16:26,031 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_prehistory\n",
      "2025-06-05:09:16:26,052 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_professional_accounting\n",
      "2025-06-05:09:16:26,072 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_professional_law\n",
      "2025-06-05:09:16:26,230 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_professional_medicine\n",
      "2025-06-05:09:16:26,255 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_professional_psychology\n",
      "2025-06-05:09:16:26,301 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_public_relations\n",
      "2025-06-05:09:16:26,309 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_security_studies\n",
      "2025-06-05:09:16:26,330 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_sociology\n",
      "2025-06-05:09:16:26,348 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_us_foreign_policy\n",
      "2025-06-05:09:16:26,355 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_virology\n",
      "2025-06-05:09:16:26,367 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: mmlu_world_religions\n",
      "2025-06-05:09:16:26,377 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: wmdp_bio\n",
      "2025-06-05:09:16:26,468 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: wmdp_chem\n",
      "2025-06-05:09:16:26,501 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: wmdp_cyber\n",
      "hf (pretrained=/home/ubuntu/thesis/code/rmu_results/layer9_alpha300.0_steer750.0,dtype=bfloat16), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
      "|                 Tasks                 |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|---------------------------------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|mmlu                                   |      2|none  |      |acc   |↑  |0.5368|±  |0.0040|\n",
      "| - humanities                          |      2|none  |      |acc   |↑  |0.4840|±  |0.0069|\n",
      "|  - formal_logic                       |      1|none  |     0|acc   |↑  |0.3810|±  |0.0434|\n",
      "|  - high_school_european_history       |      1|none  |     0|acc   |↑  |0.7152|±  |0.0352|\n",
      "|  - high_school_us_history             |      1|none  |     0|acc   |↑  |0.7206|±  |0.0315|\n",
      "|  - high_school_world_history          |      1|none  |     0|acc   |↑  |0.7553|±  |0.0280|\n",
      "|  - international_law                  |      1|none  |     0|acc   |↑  |0.6612|±  |0.0432|\n",
      "|  - jurisprudence                      |      1|none  |     0|acc   |↑  |0.6574|±  |0.0459|\n",
      "|  - logical_fallacies                  |      1|none  |     0|acc   |↑  |0.6687|±  |0.0370|\n",
      "|  - moral_disputes                     |      1|none  |     0|acc   |↑  |0.5838|±  |0.0265|\n",
      "|  - moral_scenarios                    |      1|none  |     0|acc   |↑  |0.2391|±  |0.0143|\n",
      "|  - philosophy                         |      1|none  |     0|acc   |↑  |0.5916|±  |0.0279|\n",
      "|  - prehistory                         |      1|none  |     0|acc   |↑  |0.6080|±  |0.0272|\n",
      "|  - professional_law                   |      1|none  |     0|acc   |↑  |0.3957|±  |0.0125|\n",
      "|  - world_religions                    |      1|none  |     0|acc   |↑  |0.7076|±  |0.0349|\n",
      "| - other                               |      2|none  |      |acc   |↑  |0.5909|±  |0.0084|\n",
      "|  - business_ethics                    |      1|none  |     0|acc   |↑  |0.5300|±  |0.0502|\n",
      "|  - clinical_knowledge                 |      1|none  |     0|acc   |↑  |0.5434|±  |0.0307|\n",
      "|  - college_medicine                   |      1|none  |     0|acc   |↑  |0.5896|±  |0.0375|\n",
      "|  - global_facts                       |      1|none  |     0|acc   |↑  |0.2800|±  |0.0451|\n",
      "|  - human_aging                        |      1|none  |     0|acc   |↑  |0.5874|±  |0.0330|\n",
      "|  - management                         |      1|none  |     0|acc   |↑  |0.7767|±  |0.0412|\n",
      "|  - marketing                          |      1|none  |     0|acc   |↑  |0.7949|±  |0.0265|\n",
      "|  - medical_genetics                   |      1|none  |     0|acc   |↑  |0.6100|±  |0.0490|\n",
      "|  - miscellaneous                      |      1|none  |     0|acc   |↑  |0.7676|±  |0.0151|\n",
      "|  - nutrition                          |      1|none  |     0|acc   |↑  |0.5588|±  |0.0284|\n",
      "|  - professional_accounting            |      1|none  |     0|acc   |↑  |0.4362|±  |0.0296|\n",
      "|  - professional_medicine              |      1|none  |     0|acc   |↑  |0.3382|±  |0.0287|\n",
      "|  - virology                           |      1|none  |     0|acc   |↑  |0.3855|±  |0.0379|\n",
      "| - social sciences                     |      2|none  |      |acc   |↑  |0.6490|±  |0.0083|\n",
      "|  - econometrics                       |      1|none  |     0|acc   |↑  |0.3509|±  |0.0449|\n",
      "|  - high_school_geography              |      1|none  |     0|acc   |↑  |0.7273|±  |0.0317|\n",
      "|  - high_school_government_and_politics|      1|none  |     0|acc   |↑  |0.7824|±  |0.0298|\n",
      "|  - high_school_macroeconomics         |      1|none  |     0|acc   |↑  |0.5744|±  |0.0251|\n",
      "|  - high_school_microeconomics         |      1|none  |     0|acc   |↑  |0.5630|±  |0.0322|\n",
      "|  - high_school_psychology             |      1|none  |     0|acc   |↑  |0.8018|±  |0.0171|\n",
      "|  - human_sexuality                    |      1|none  |     0|acc   |↑  |0.6565|±  |0.0416|\n",
      "|  - professional_psychology            |      1|none  |     0|acc   |↑  |0.5327|±  |0.0202|\n",
      "|  - public_relations                   |      1|none  |     0|acc   |↑  |0.6273|±  |0.0463|\n",
      "|  - security_studies                   |      1|none  |     0|acc   |↑  |0.6286|±  |0.0309|\n",
      "|  - sociology                          |      1|none  |     0|acc   |↑  |0.7612|±  |0.0301|\n",
      "|  - us_foreign_policy                  |      1|none  |     0|acc   |↑  |0.7900|±  |0.0409|\n",
      "| - stem                                |      2|none  |      |acc   |↑  |0.4529|±  |0.0086|\n",
      "|  - abstract_algebra                   |      1|none  |     0|acc   |↑  |0.2900|±  |0.0456|\n",
      "|  - anatomy                            |      1|none  |     0|acc   |↑  |0.5037|±  |0.0432|\n",
      "|  - astronomy                          |      1|none  |     0|acc   |↑  |0.5658|±  |0.0403|\n",
      "|  - college_biology                    |      1|none  |     0|acc   |↑  |0.6736|±  |0.0392|\n",
      "|  - college_chemistry                  |      1|none  |     0|acc   |↑  |0.4800|±  |0.0502|\n",
      "|  - college_computer_science           |      1|none  |     0|acc   |↑  |0.3700|±  |0.0485|\n",
      "|  - college_mathematics                |      1|none  |     0|acc   |↑  |0.4100|±  |0.0494|\n",
      "|  - college_physics                    |      1|none  |     0|acc   |↑  |0.2843|±  |0.0449|\n",
      "|  - computer_security                  |      1|none  |     0|acc   |↑  |0.4300|±  |0.0498|\n",
      "|  - conceptual_physics                 |      1|none  |     0|acc   |↑  |0.4468|±  |0.0325|\n",
      "|  - electrical_engineering             |      1|none  |     0|acc   |↑  |0.5103|±  |0.0417|\n",
      "|  - elementary_mathematics             |      1|none  |     0|acc   |↑  |0.3995|±  |0.0252|\n",
      "|  - high_school_biology                |      1|none  |     0|acc   |↑  |0.6742|±  |0.0267|\n",
      "|  - high_school_chemistry              |      1|none  |     0|acc   |↑  |0.4236|±  |0.0348|\n",
      "|  - high_school_computer_science       |      1|none  |     0|acc   |↑  |0.5000|±  |0.0503|\n",
      "|  - high_school_mathematics            |      1|none  |     0|acc   |↑  |0.3519|±  |0.0291|\n",
      "|  - high_school_physics                |      1|none  |     0|acc   |↑  |0.2914|±  |0.0371|\n",
      "|  - high_school_statistics             |      1|none  |     0|acc   |↑  |0.4815|±  |0.0341|\n",
      "|  - machine_learning                   |      1|none  |     0|acc   |↑  |0.2857|±  |0.0429|\n",
      "|wmdp                                   |      1|none  |      |acc   |↑  |0.3345|±  |0.0077|\n",
      "| - wmdp_bio                            |      1|none  |     0|acc   |↑  |0.4124|±  |0.0138|\n",
      "| - wmdp_chem                           |      1|none  |     0|acc   |↑  |0.3873|±  |0.0241|\n",
      "| - wmdp_cyber                          |      1|none  |     0|acc   |↑  |0.2738|±  |0.0100|\n",
      "\n",
      "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
      "|mmlu              |      2|none  |      |acc   |↑  |0.5368|±  |0.0040|\n",
      "| - humanities     |      2|none  |      |acc   |↑  |0.4840|±  |0.0069|\n",
      "| - other          |      2|none  |      |acc   |↑  |0.5909|±  |0.0084|\n",
      "| - social sciences|      2|none  |      |acc   |↑  |0.6490|±  |0.0083|\n",
      "| - stem           |      2|none  |      |acc   |↑  |0.4529|±  |0.0086|\n",
      "|wmdp              |      1|none  |      |acc   |↑  |0.3345|±  |0.0077|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!uv run lm-eval --model hf \\\n",
    "    --model_args pretrained=\"/home/ubuntu/thesis/code/rmu_results/layer9_alpha300.0_steer750.0\",dtype=bfloat16 \\\n",
    "    --tasks mmlu,wmdp \\\n",
    "    --log_samples \\\n",
    "    --output_path \"eval/gemma-2b\" \\\n",
    "    --batch_size=8 \\\n",
    "    --seed 42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
