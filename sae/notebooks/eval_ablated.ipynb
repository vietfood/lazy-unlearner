{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c471e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from datasets import concatenate_datasets, load_from_disk\n",
    "import numpy as np\n",
    "\n",
    "from sae_refusal.model.gemma import GemmaModel\n",
    "from sae_refusal.model.embedding import EmbeddingModel\n",
    "from sae_refusal import set_seed, clear_memory\n",
    "from sae_refusal.data import (\n",
    "    load_wmdp,\n",
    "    split,\n",
    "    to_instructions,\n",
    "    sample_data,\n",
    "    load_harmbench\n",
    ")\n",
    "from sae_refusal.pipeline.select_directions import select_direction, get_junk_scores\n",
    "from sae_refusal.pipeline.utils import compute_pca, generate_and_save_completions, proj, evaluate_multiple_choice\n",
    "from sae_refusal.probe import LinearProbe\n",
    "from sae_refusal.pipeline.generate_directions import generate_directions_rmu\n",
    "from sae_refusal.pipeline.hook import (\n",
    "    get_all_direction_ablation_hooks,\n",
    "    get_all_direction_ablation_hooks_rmu,\n",
    "    get_activation_addition_input_pre_hook,\n",
    "    get_activation_addition_input_pre_hook_rmu\n",
    ")\n",
    "from sae_refusal.plot import (\n",
    "    plot_scores_plotly,\n",
    "    plot_refusal_scores_plotly,\n",
    ")\n",
    "from sae_refusal.pipeline.activations import (\n",
    "    get_activations,\n",
    "    get_activations_pre\n",
    ")\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5969be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_ID = 9\n",
    "SAMPLE_SIZE = 300  # For each dataset\n",
    "VAL_SIZE = 0.2\n",
    "SEED = 42\n",
    "MAX_LEN = 1024\n",
    "\n",
    "ARTIFACT_DIR = \"results/ablated\"\n",
    "\n",
    "MODEL_NAME = \"google/gemma-2-2b\"\n",
    "RMU_NAME = \"lenguyen1807/gemma-2-2b-RMU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93d93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca0c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = \"base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c9423",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45ddc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4cd6f65e9a48a88d7b22026cd9afeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmu_model = GemmaModel(RMU_NAME, type=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1ae0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_weight = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/probes/best_probes/weight.pt\", weights_only=True)\n",
    "probe = LinearProbe(rmu_model.model.config.hidden_size)\n",
    "probe.load_state_dict(probe_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b123f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/probes/best_probes/mean.pt\", weights_only=True)\n",
    "std = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/probes/best_probes/std.pt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826829d7",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ca404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_test = load_from_disk(\"/home/ubuntu/thesis/sae/results/ablated/data/t_bio\")\n",
    "cyber_test = load_from_disk(\"/home/ubuntu/thesis/sae/results/ablated/data/t_cyber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4a35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_final = load_from_disk(\"/home/ubuntu/thesis/sae/results/ablated/data/left_bio\")\n",
    "cyber_final = load_from_disk(\"/home/ubuntu/thesis/sae/results/ablated/data/left_cyber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4b47b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 1087)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bio_final), len(cyber_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45332f",
   "metadata": {},
   "source": [
    "### Load directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9964d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = dict()\n",
    "\n",
    "for dir in [\"bio\", \"cyber\", \"general\", \"shared\", \"general_same\"]:\n",
    "    path = f\"/home/ubuntu/thesis/sae/results/ablated/direction_{dir}\"\n",
    "    best_dir = torch.load(f\"{path}/best_dir.pt\", weights_only=True)\n",
    "    rand_dir = torch.load(f\"{path}/rand.pt\", weights_only=True)\n",
    "\n",
    "    # best hooks\n",
    "    best_pre_hooks, best_hooks = get_all_direction_ablation_hooks_rmu(\n",
    "        model_base=rmu_model,\n",
    "        directions=[best_dir]\n",
    "    )\n",
    "\n",
    "    # rand hooks\n",
    "    rand_pre_hooks, rand_hooks = get_all_direction_ablation_hooks_rmu(\n",
    "        model_base=rmu_model,\n",
    "        directions=[rand_dir]\n",
    "    )\n",
    "\n",
    "    all_dirs[dir] = {\n",
    "        \"best_dir\": best_dir,\n",
    "        \"rand_dir\": rand_dir,\n",
    "        \"pre_hooks\": best_pre_hooks,\n",
    "        \"hooks\": best_hooks,\n",
    "        \"rand_pre_hook\": rand_pre_hooks,\n",
    "        \"rand_hooks\": rand_hooks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30365da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def t_test(results_treatment, results_control, alpha=0.05, alternative='two-sided'):\n",
    "    t_statistic, p_value = stats.ttest_rel(results_treatment, results_control, alternative=alternative)\n",
    "\n",
    "    print(f\"T-statistic: {t_statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "\n",
    "    # Interpret the result\n",
    "    if p_value < alpha:\n",
    "        print(\"The result is statistically significant.\")\n",
    "        if alternative == 'less':\n",
    "            print(\"We reject the null hypothesis: the treatment intervention is significantly less than the control.\")\n",
    "        elif alternative == 'greater':\n",
    "            print(\"We reject the null hypothesis: the treatment intervention is significantly greater than the control.\")\n",
    "        else:\n",
    "            print(\"We reject the null hypothesis: the interventions have a different effect.\")\n",
    "    else:\n",
    "        print(\"The result is not statistically significant.\")\n",
    "        print(\"We fail to reject the null hypothesis: we cannot conclude the interventions have a different effect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d19424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "junk_fn = partial(\n",
    "    get_junk_scores,\n",
    "    model=rmu_model,\n",
    "    probe=probe.to(rmu_model.model.device),\n",
    "    probe_mean=mean.to(rmu_model.model.device),\n",
    "    probe_std=std.to(rmu_model.model.device),\n",
    "    junk_layer=LAYER_ID + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18e4d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_junk_scores(all_dirs, type=\"shared\"):\n",
    "    bio_junk = junk_fn(\n",
    "        instructions=bio_test[\"question\"],\n",
    "        fwd_pre_hooks=all_dirs[type][\"pre_hooks\"],\n",
    "        fwd_hooks=all_dirs[type][\"hooks\"],\n",
    "        batch_size=8\n",
    "    ) \n",
    "\n",
    "    cyber_junk = junk_fn(\n",
    "        instructions=cyber_test[\"question\"],\n",
    "        fwd_pre_hooks=all_dirs[type][\"pre_hooks\"],\n",
    "        fwd_hooks=all_dirs[type][\"hooks\"],\n",
    "        batch_size=8\n",
    "    ) \n",
    "\n",
    "    bio_rand_junk = junk_fn(\n",
    "        instructions=bio_test[\"question\"],\n",
    "        fwd_pre_hooks=all_dirs[type][\"rand_pre_hook\"],\n",
    "        fwd_hooks=all_dirs[type][\"rand_hooks\"],\n",
    "        batch_size=8\n",
    "    ) \n",
    "\n",
    "    cyber_rand_junk = junk_fn(\n",
    "        instructions=cyber_test[\"question\"],\n",
    "        fwd_pre_hooks=all_dirs[type][\"rand_pre_hook\"],\n",
    "        fwd_hooks=all_dirs[type][\"rand_hooks\"],\n",
    "        batch_size=8\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        \"bio\": (bio_junk.cpu().numpy(), bio_rand_junk.cpu().numpy()),\n",
    "        \"cyber\": (cyber_junk.cpu().numpy(), cyber_rand_junk.cpu().numpy())\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b8a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qa(model, all_dirs, type=\"shared\", base=False, rand=False):\n",
    "    if base:\n",
    "        fwd_pre_hooks = []\n",
    "        fwd_hooks = []\n",
    "    elif rand:\n",
    "        fwd_pre_hooks = all_dirs[type][\"rand_pre_hook\"]\n",
    "        fwd_hooks = all_dirs[type][\"rand_hooks\"]\n",
    "    else:\n",
    "        fwd_pre_hooks = all_dirs[type][\"pre_hooks\"]\n",
    "        fwd_hooks = all_dirs[type][\"hooks\"]\n",
    "\n",
    "    cyber_results = evaluate_multiple_choice(\n",
    "        model=model,\n",
    "        questions=cyber_final[\"question\"],\n",
    "        choices=cyber_final[\"choices\"],\n",
    "        ground_truth_indices=cyber_final[\"answer\"],\n",
    "        fwd_pre_hooks=fwd_pre_hooks,\n",
    "        fwd_hooks=fwd_hooks,\n",
    "        batch_size=2,\n",
    "    )\n",
    "\n",
    "    bio_results = evaluate_multiple_choice(\n",
    "        model=model,\n",
    "        questions=bio_final[\"question\"],\n",
    "        choices=bio_final[\"choices\"],\n",
    "        ground_truth_indices=bio_final[\"answer\"],\n",
    "        fwd_pre_hooks=fwd_pre_hooks,\n",
    "        fwd_hooks=fwd_hooks,\n",
    "        batch_size=32,\n",
    "    )\n",
    "\n",
    "    return {\"bio\": bio_results, \"cyber\": cyber_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd03306",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5bfe250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957b9c93b1a4442a99cd41147e412c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f29cebb3f19460a8529dda48fe8e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating MCQA Pairs:   0%|          | 0/2174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3f2928d4234d3193a320aaa14294f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating MCQA Pairs:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TYPE == \"rmu\":\n",
    "    results = evaluate_qa(model=rmu_model, all_dirs=all_dirs, base=True)\n",
    "elif TYPE == \"base\":\n",
    "    rmu_model.model.to(\"cpu\")\n",
    "    base_model = GemmaModel(MODEL_NAME, type=\"none\")\n",
    "    results = evaluate_qa(model=base_model, all_dirs=all_dirs, base=True)\n",
    "else:\n",
    "    results = evaluate_qa(model=rmu_model, all_dirs=all_dirs, type=TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f76317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for direction type: base\n",
      "--- Bio ---\n",
      "Accuracy: 0.3324396782841823\n",
      "--- Cyber ---\n",
      "Accuracy: 0.43698252069917204\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results for direction type: {TYPE}\")\n",
    "print(\"--- Bio ---\")\n",
    "print(f\"Accuracy: {results['bio'][0]}\")\n",
    "\n",
    "print(\"--- Cyber ---\")\n",
    "print(f\"Accuracy: {results['cyber'][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
