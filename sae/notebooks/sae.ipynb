{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02ae66b-862e-46a4-84b2-f639bb0e0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from datasets import load_from_disk\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sae_refusal.model.gemma import GemmaModel\n",
    "from sae_refusal.model.embedding import EmbeddingModel\n",
    "from sae_refusal import set_seed, clear_memory\n",
    "from sae_refusal.data import (\n",
    "    load_wmdp,\n",
    "    split,\n",
    "    to_instructions,\n",
    "    sample_data,\n",
    "    format_qa\n",
    ")\n",
    "from sae_refusal.probe import LinearProbe\n",
    "from sae_refusal.pipeline.generate_directions import generate_directions_rmu\n",
    "from sae_refusal.plot import (\n",
    "    plot_scores_plotly,\n",
    "    plot_refusal_scores_plotly,\n",
    ")\n",
    "from sae_refusal.pipeline.activations import (\n",
    "    get_activations,\n",
    "    get_activations_pre,\n",
    "    get_sae_encoded_features,\n",
    "    get_refusal_gradients,\n",
    "    get_sae_reconstructed_pre\n",
    ")\n",
    "from sae_refusal.sae import (\n",
    "    load_sae_gemma_2b,\n",
    "    layer_sparisity_widths\n",
    ")\n",
    "from sae_refusal.pipeline.utils import (\n",
    "    generate_and_save_completions\n",
    ")\n",
    "from sae_refusal.plot import (\n",
    "    plot_scores_plotly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f95b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_ID = 9\n",
    "SAMPLE_SIZE = 300  # For each dataset\n",
    "VAL_SIZE = 0.2\n",
    "SEED = 42\n",
    "MAX_LEN = 1024\n",
    "\n",
    "ARTIFACT_DIR = \"results/ablated/\"\n",
    "\n",
    "MODEL_NAME = \"google/gemma-2-2b\"\n",
    "RMU_NAME = \"lenguyen1807/gemma-2-2b-RMU\"\n",
    "ABLATED_NAME = \"lenguyen1807/gemma-2-2b-RMU-ablated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0c396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b875b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = \"cyber\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f077b55",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79eee4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ce0fa74af3412eb7cc43f201979a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc93bfe210424a048bcc3fde113b16e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735fbdfed6294364979fa6f926296b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = GemmaModel(MODEL_NAME, type=\"none\")\n",
    "rmu_model = GemmaModel(RMU_NAME, type=\"none\")\n",
    "ablated_model = GemmaModel(ABLATED_NAME, type=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e19b2f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_weight = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/probes/best_probes/weight.pt\", weights_only=True)\n",
    "probe = LinearProbe(base_model.model.config.hidden_size)\n",
    "probe.load_state_dict(probe_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fadbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/probes/best_probes/mean.pt\", weights_only=True)\n",
    "std = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/probes/best_probes/std.pt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee5aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_diff = torch.load(\"/home/ubuntu/thesis/sae/results/ablated/direction_shared/best_dir.pt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74cddd",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04069fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_test = load_from_disk(\"/home/ubuntu/thesis/sae/results/ablated/data/t_bio\")\n",
    "cyber_test = load_from_disk(\"/home/ubuntu/thesis/sae/results/ablated/data/t_cyber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e654979",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_raw = bio_test[\"question\"]\n",
    "cyber_raw = cyber_test[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19455daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_reason = [format_qa(bio) for bio in bio_test]\n",
    "cyber_reason = [format_qa(cyber) for cyber in cyber_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d06a7a",
   "metadata": {},
   "source": [
    "### Junk Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38897fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_grad = get_refusal_gradients(\n",
    "    model=base_model.model,\n",
    "    tokenize_instructions_fn=base_model.tokenize_instructions_fn,\n",
    "    block_modules=base_model.model_block_modules,\n",
    "    prompts=bio_raw if TYPE == \"bio\" else cyber_raw,\n",
    "    refusal_direction=best_diff,\n",
    "    gradient_layer_idx=5,\n",
    "    refusal_layer_idx=LAYER_ID,\n",
    "    batch_size=1,\n",
    "    positions=[-5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d056f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablated_grad = get_refusal_gradients(\n",
    "    model=ablated_model.model,\n",
    "    tokenize_instructions_fn=ablated_model.tokenize_instructions_fn,\n",
    "    block_modules=ablated_model.model_block_modules,\n",
    "    prompts=bio_raw if TYPE == \"bio\" else cyber_raw,\n",
    "    refusal_direction=best_diff,\n",
    "    gradient_layer_idx=5,\n",
    "    refusal_layer_idx=LAYER_ID,\n",
    "    batch_size=1,\n",
    "    positions=[-5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmu_grad = get_refusal_gradients(\n",
    "    model=rmu_model.model,\n",
    "    tokenize_instructions_fn=rmu_model.tokenize_instructions_fn,\n",
    "    block_modules=rmu_model.model_block_modules,\n",
    "    prompts=bio_raw if TYPE == \"bio\" else cyber_raw,\n",
    "    refusal_direction=best_diff,\n",
    "    gradient_layer_idx=5,\n",
    "    refusal_layer_idx=LAYER_ID,\n",
    "    batch_size=1,\n",
    "    positions=[-5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9274d",
   "metadata": {},
   "source": [
    "### Load SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b87e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sae_dict = dict()\n",
    "# for layer in range(base_model.model.config.num_hidden_layers):\n",
    "#     sae_dict[layer] = load_sae_gemma_2b(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a879e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_layer = load_sae_gemma_2b(layer_id=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62b491",
   "metadata": {},
   "source": [
    "#### SAE Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5515d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_layer_decoder = sae_layer.state_dict()[\"W_dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567effa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cosine = torch.nn.functional.cosine_similarity(base_grad.to(sae_layer_decoder.device), sae_layer_decoder, dim=-1)\n",
    "ablated_cosine = torch.nn.functional.cosine_similarity(ablated_grad.to(sae_layer_decoder.device), sae_layer_decoder, dim=-1)\n",
    "rmu_cosine = torch.nn.functional.cosine_similarity(rmu_grad.to(sae_layer_decoder.device), sae_layer_decoder, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_histogram(\n",
    "    similarities,\n",
    "    artifact_dir,\n",
    "    type = \"Bio\",\n",
    "    k: int = 10,\n",
    "    figsize = (10, 6)\n",
    "):\n",
    "    if similarities.ndim != 1:\n",
    "        raise ValueError(\"similarities tensor must be 1-dimensional\")\n",
    "\n",
    "    sims_numpy = similarities.cpu().numpy()\n",
    "\n",
    "    # --- 1. Find the top and bottom k features ---\n",
    "    top_k = torch.topk(similarities, k=k, largest=True)\n",
    "    bottom_k = torch.topk(similarities, k=k, largest=False)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- 2. Add the main histogram trace ---\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=sims_numpy,\n",
    "            nbinsx=100,  # Increased bins for better resolution\n",
    "            name=\"All Features\",\n",
    "            opacity=0.7,\n",
    "            marker=dict(line_width=1, line_color=\"white\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- 3. Add vertical lines for top and bottom features ---\n",
    "    for i in range(k):\n",
    "        # Top k lines (blue, dotted)\n",
    "        fig.add_vline(\n",
    "            x=top_k.values[i].item(),\n",
    "            line_width=2,\n",
    "            line_dash=\"dot\",\n",
    "            line_color=\"royalblue\",\n",
    "        )\n",
    "        # Bottom k lines (red, dotted)\n",
    "        fig.add_vline(\n",
    "            x=bottom_k.values[i].item(),\n",
    "            line_width=2,\n",
    "            line_dash=\"dot\",\n",
    "            line_color=\"firebrick\",\n",
    "        )\n",
    "\n",
    "    # --- 4. Add annotation boxes for the indices ---\n",
    "    # Create the text for the annotation boxes\n",
    "    top_k_text = \"<b>Top {} Indices</b><br>\".format(k) + \"<br>\".join([str(i.item()) for i in top_k.indices])\n",
    "    bottom_k_text = \"<b>Bottom {} Indices</b><br>\".format(k) + \"<br>\".join([str(i.item()) for i in bottom_k.indices])\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=top_k_text,\n",
    "        align='left',\n",
    "        showarrow=False,\n",
    "        xref='paper',  # Use paper coordinates for x positioning\n",
    "        yref='paper',  # Use paper coordinates for y positioning\n",
    "        x=0.98,        # Positioned at 98% from the left edge of the plot\n",
    "        y=0.95,        # Positioned at 95% from the bottom edge of the plot\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.8)\" # Slightly transparent background\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=bottom_k_text,\n",
    "        align='left',\n",
    "        showarrow=False,\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        x=0.02,        # Positioned at 2% from the left edge\n",
    "        y=0.95,\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
    "    )\n",
    "\n",
    "    # --- 5. Final layout updates ---\n",
    "    fig.update_layout(\n",
    "        title=f\"Cosine Similarity Between SAE Latents and Refusal Gradients ({type})\",\n",
    "        xaxis_title=\"Cosine Similarity\",\n",
    "        yaxis_title=\"Count\",\n",
    "        barmode=\"overlay\",\n",
    "        bargap=0.1,\n",
    "        width=figsize[0]*100,\n",
    "        height=figsize[1]*100,\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_image(artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_histogram(base_cosine, artifact_dir=f\"{ARTIFACT_DIR}/{TYPE}_cosine_latents_base.pdf\", type=TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_histogram(rmu_cosine, artifact_dir=f\"{ARTIFACT_DIR}/{TYPE}_cosine_latents_rmu.pdf\", type=TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_histogram(ablated_cosine, artifact_dir=f\"{ARTIFACT_DIR}/{TYPE}_cosine_latents_ablated.pdf\", type=TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20609353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release, sae_id, feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "html = get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"5-gemmascope-res-16k\", feature_idx=12187)\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f3056",
   "metadata": {},
   "source": [
    "### Steering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912eaf0",
   "metadata": {},
   "source": [
    "CYBER: 4101, 2502 \n",
    "BIO: 16213, 8085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1c5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_dir_1 = sae_layer_decoder[16213]\n",
    "steer_dir_2 = sae_layer_decoder[8085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4799792",
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_dir = (steer_dir_1 + steer_dir_2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d411fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablated_model.mod_model(steer_dir, type=\"ablation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12759b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OrderedVocab you are attempting to save contains holes for indices [0], your vocabulary could be corrupted !\n"
     ]
    }
   ],
   "source": [
    "ablated_model.save(\"/home/ubuntu/thesis/sae/results/models/sae_steer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
